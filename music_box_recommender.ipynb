{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Data Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import pyspark.sql.functions as F\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+--------+----------+---------+-----------+\n",
      "|      uid|device| song_id|      date|play_time|song_length|\n",
      "+---------+------+--------+----------+---------+-----------+\n",
      "|168551247|    ar|11881432|2017-03-30|       78|        149|\n",
      "|168549788|    ip|  295469|2017-03-30|       16|        242|\n",
      "|168543026|    ar| 6623026|2017-03-30|        0|          0|\n",
      "|168550571|    ar|       0|2017-03-30|       24|        251|\n",
      "|168548101|    ip| 6913185|2017-03-30|       40|        198|\n",
      "+---------+------+--------+----------+---------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_play = spark.read.csv('../data/play_ds.csv',header=True)\n",
    "df_play.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_play_time = df_play.withColumn(\"play_time_tot\", F.when(\n",
    "    F.col('play_time')<=0, 0\n",
    ").otherwise(F.col('play_time')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate ratings of each user i to each song j as :\n",
    " (total play time of user i to song j)/ (user i's longest playing time of all songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playtime_generation(df):\n",
    "\n",
    "    df_play_time = df \\\n",
    "        .groupBy('uid','song_id') \\\n",
    "        .agg(F.sum(F.col('play_time_tot')).alias('playtime_tot') \n",
    "            )\n",
    "    return df_play_time\n",
    "\n",
    "df_ratings_time = playtime_generation(df_play_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_tmp = df_ratings_time.groupBy('uid').agg(F.max(F.col('playtime_tot')).alias('max_playtime'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_rating is the long format of the ratings\n",
    "df_ratings = df_ratings_time.join(df_ratings_tmp,on='uid',how='left')\n",
    "df_rating = df_ratings.withColumn('ratings', F.col('playtime_tot')/F.col('max_playtime')).select('uid','song_id','ratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_rating.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-------------------+\n",
      "|     uid| song_id|            ratings|\n",
      "+--------+--------+-------------------+\n",
      "|11596711|15807836|0.06303972366148532|\n",
      "|11596711|  169744|0.14709268854346574|\n",
      "|11596711|  149745| 0.1079447322970639|\n",
      "+--------+--------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rating.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove missing values from df_ratings.\n",
    "The missingness is from the down-sampled play_ds.csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3093222\n"
     ]
    }
   ],
   "source": [
    "df_rating2 = df_rating.filter(~(df_rating[\"ratings\"].isNull() | df_rating[\"song_id\"].isNull()))\n",
    "print(df_rating2.filter(df_rating2[\"ratings\"].isNull() ).count())\n",
    "print(df_rating2.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert uid and song_id to interger format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('uid', 'string'), ('song_id', 'string'), ('ratings', 'double')]\n",
      "[('uid', 'int'), ('song_id', 'int'), ('ratings', 'double')]\n"
     ]
    }
   ],
   "source": [
    "# df_rating2[\"ratings\"].max()\n",
    "# print(df_rating2.agg({\"ratings\": \"max\"}).collect())\n",
    "# print(df_rating2.agg({\"song_id\": \"max\"}).collect())\n",
    "# print(df_rating2.agg({\"uid\": \"max\"}).collect())\n",
    "print(df_rating2.dtypes)\n",
    "from pyspark.sql.types import IntegerType\n",
    "df_rating3 = df_rating2.withColumn(\n",
    "    \"uid\", df_rating2[\"uid\"].cast(IntegerType())\n",
    "    ).withColumn(\n",
    "    \"song_id\", df_rating2[\"song_id\"].cast(IntegerType())\n",
    "    ).dropna()\n",
    "print(df_rating3.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rating3.show()\n",
    "# df_rating3.subtract(df_rating3.dropna()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating3.toPandas().to_csv('../data/df_rating.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model with spark ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training, test) = df_rating3.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ALS.train(training.rdd, rank = 10, iterations = 5, lambda_=0.01)\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"uid\", itemCol=\"song_id\", ratingCol=\"ratings\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "model1 = als.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.19986818827118968\n"
     ]
    }
   ],
   "source": [
    "predictions = model1.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"ratings\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|       avg(ratings)|\n",
      "+-------------------+\n",
      "|0.14028382220048344|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.agg(F.mean('ratings')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
